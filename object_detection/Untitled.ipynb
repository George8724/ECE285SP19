{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    " \n",
    "r\"\"\"Convert raw PASCAL dataset to TFRecord for object_detection.\n",
    "Example usage:\n",
    "    ./create_pascal_tf_record --data_dir=/home/user/VOCdevkit \\\n",
    "        --year=VOC2012 \\\n",
    "        --output_path=/home/user/pascal.record\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    " \n",
    "import hashlib\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    " \n",
    "from lxml import etree\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    " \n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    " \n",
    " \n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('data_dir', '', 'Root directory to raw PASCAL VOC dataset.')\n",
    "flags.DEFINE_string('set', 'train', 'Convert training set, validation set or '\n",
    "                    'merged set.')\n",
    "flags.DEFINE_string('annotations_dir', 'Annotations',\n",
    "                    '(Relative) path to annotations directory.')\n",
    "flags.DEFINE_string('year', 'VOC2007', 'Desired challenge year.')\n",
    "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
    "flags.DEFINE_string('label_map_path', 'object_detection/data/pascal_label_map.pbtxt',\n",
    "                    'Path to label map proto')\n",
    "flags.DEFINE_boolean('ignore_difficult_instances', False, 'Whether to ignore '\n",
    "                     'difficult instances')\n",
    "FLAGS = flags.FLAGS\n",
    " \n",
    "SETS = ['train', 'val', 'trainval', 'test']\n",
    "YEARS = ['VOC2007', 'VOC2012', 'merged']\n",
    " \n",
    " \n",
    "def dict_to_tf_example(data,\n",
    "                       dataset_directory,\n",
    "                       label_map_dict,\n",
    "                       ignore_difficult_instances=False,\n",
    "                       image_subdirectory='JPEGImages'):\n",
    "  \"\"\"Convert XML derived dict to tf.Example proto.\n",
    "  Notice that this function normalizes the bounding box coordinates provided\n",
    "  by the raw data.\n",
    "  Args:\n",
    "    data: dict holding PASCAL XML fields for a single image (obtained by\n",
    "      running dataset_util.recursive_parse_xml_to_dict)\n",
    "    dataset_directory: Path to root directory holding PASCAL dataset\n",
    "    label_map_dict: A map from string label names to integers ids.\n",
    "    ignore_difficult_instances: Whether to skip difficult instances in the\n",
    "      dataset  (default: False).\n",
    "    image_subdirectory: String specifying subdirectory within the\n",
    "      PASCAL dataset directory holding the actual image data.\n",
    "  Returns:\n",
    "    example: The converted tf.Example.\n",
    "  Raises:\n",
    "    ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n",
    "  \"\"\"\n",
    "  img_path = os.path.join(data['folder'], image_subdirectory, data['filename'])\n",
    "  full_path = os.path.join(dataset_directory, img_path)\n",
    "  with tf.gfile.GFile(full_path, 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "  image = PIL.Image.open(encoded_jpg_io)\n",
    "  if image.format != 'JPEG':\n",
    "    raise ValueError('Image format not JPEG')\n",
    "  key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    " \n",
    "  width = int(data['size']['width'])\n",
    "  height = int(data['size']['height'])\n",
    " \n",
    "  xmin = []\n",
    "  ymin = []\n",
    "  xmax = []\n",
    "  ymax = []\n",
    "  classes = []\n",
    "  classes_text = []\n",
    "  truncated = []\n",
    "  poses = []\n",
    "  difficult_obj = []\n",
    "  for obj in data['object']:\n",
    "    difficult = bool(int(obj['difficult']))\n",
    "    if ignore_difficult_instances and difficult:\n",
    "      continue\n",
    " \n",
    "    difficult_obj.append(int(difficult))\n",
    " \n",
    "    xmin.append(float(obj['bndbox']['xmin']) / width)\n",
    "    ymin.append(float(obj['bndbox']['ymin']) / height)\n",
    "    xmax.append(float(obj['bndbox']['xmax']) / width)\n",
    "    ymax.append(float(obj['bndbox']['ymax']) / height)\n",
    "    classes_text.append(obj['name'].encode('utf8'))\n",
    "    classes.append(label_map_dict[obj['name']])\n",
    "    truncated.append(int(obj['truncated']))\n",
    "    poses.append(obj['pose'].encode('utf8'))\n",
    " \n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(\n",
    "          data['filename'].encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(\n",
    "          data['filename'].encode('utf8')),\n",
    "      'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "      'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "      'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "      'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "  }))\n",
    "  return example\n",
    " \n",
    " \n",
    "def main(_):\n",
    "  if FLAGS.set not in SETS:\n",
    "    raise ValueError('set must be in : {}'.format(SETS))\n",
    "  if FLAGS.year not in YEARS:\n",
    "    raise ValueError('year must be in : {}'.format(YEARS))\n",
    " \n",
    "  data_dir = FLAGS.data_dir\n",
    "  years = ['VOC2007', 'VOC2012']\n",
    "  if FLAGS.year != 'merged':\n",
    "    years = [FLAGS.year]\n",
    " \n",
    "  writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
    " \n",
    "  label_map_dict = label_map_util.get_label_map_dict(FLAGS.label_map_path)\n",
    " \n",
    "  for year in years:\n",
    "    logging.info('Reading from PASCAL %s dataset.', year)\n",
    "    examples_path = os.path.join(data_dir, year, 'ImageSets', 'Main',\n",
    "                                 'aeroplane_' + FLAGS.set + '.txt')\n",
    "    annotations_dir = os.path.join(data_dir, year, FLAGS.annotations_dir)\n",
    "    examples_list = dataset_util.read_examples_list(examples_path)\n",
    "    for idx, example in enumerate(examples_list):\n",
    "      if idx % 100 == 0:\n",
    "        logging.info('On image %d of %d', idx, len(examples_list))\n",
    "      path = os.path.join(annotations_dir, example + '.xml')\n",
    "      with tf.gfile.GFile(path, 'r') as fid:\n",
    "        xml_str = fid.read()\n",
    "      xml = etree.fromstring(xml_str)\n",
    "      data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']\n",
    " \n",
    "      tf_example = dict_to_tf_example(data, FLAGS.data_dir, label_map_dict,\n",
    "                                      FLAGS.ignore_difficult_instances)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    " \n",
    "  writer.close()\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
